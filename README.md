# PyTorch Profiler: CPU & GPU Performance Analysis

Este repositorio muestra **cÃ³mo usar `torch.profiler` de forma prÃ¡ctica y progresiva**
para analizar **tiempo, memoria y ejecuciÃ³n** de un modelo de deep learning en PyTorch.

El ejemplo utiliza **ResNet-18** con datos sintÃ©ticos y cubre:
- Profiling en CPU
- Profiling en GPU (CUDA / XPU)
- Uso de memoria
- ExportaciÃ³n de trazas
- Stack traces
- Schedules de profiling

---

## ğŸ§  Â¿QuÃ© se aprende en este repo?

âœ”ï¸ CÃ³mo perfilar inferencia de un modelo en CPU  
âœ”ï¸ CÃ³mo identificar cuellos de botella en GPU  
âœ”ï¸ Diferencia entre tiempo real de cÃ³mputo y sincronizaciÃ³n  
âœ”ï¸ CÃ³mo analizar uso de memoria  
âœ”ï¸ CÃ³mo generar trazas visuales (`trace.json`)  
âœ”ï¸ CÃ³mo usar `schedule` para profiling en loops reales  

---

ğŸ§© Requisitos

Antes de ejecutar el script, instala las dependencias:

pip install -r requirements.txt

ğŸ§‘â€ğŸ’» Autor

Desarrollado por Gus como parte de su aprendizaje en Python e IA.
